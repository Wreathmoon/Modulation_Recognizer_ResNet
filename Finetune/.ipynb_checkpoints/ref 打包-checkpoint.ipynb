{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e060e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the number of cpus used by high performance libraries\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './yolov5')\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import platform\n",
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from yolov5.models.experimental import attempt_load\n",
    "from yolov5.utils.downloads import attempt_download\n",
    "from yolov5.models.common import DetectMultiBackend\n",
    "from yolov5.utils.datasets import LoadImages, LoadStreams, VID_FORMATS\n",
    "from yolov5.utils.general import (LOGGER, check_img_size, non_max_suppression, scale_coords,\n",
    "                                  check_imshow, xyxy2xywh, increment_path, strip_optimizer, colorstr)\n",
    "from yolov5.utils.torch_utils import select_device, time_sync\n",
    "from yolov5.utils.plots import Annotator, colors, save_one_box\n",
    "from deep_sort.utils.parser import get_config\n",
    "from deep_sort.deep_sort import DeepSort\n",
    "\n",
    "FILE = Path(__file__).resolve()\n",
    "ROOT = FILE.parents[0]  # yolov5 deepsort root directory\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))  # add ROOT to PATH\n",
    "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\n",
    "\n",
    "\n",
    "def detect(opt):\n",
    "    out, source, yolo_model, deep_sort_model, show_vid, save_vid, save_txt, imgsz, evaluate, half, \\\n",
    "        project, exist_ok, update, save_crop = \\\n",
    "        opt.output, opt.source, opt.yolo_model, opt.deep_sort_model, opt.show_vid, opt.save_vid, \\\n",
    "        opt.save_txt, opt.imgsz, opt.evaluate, opt.half, opt.project, opt.exist_ok, opt.update, opt.save_crop\n",
    "    webcam = source == '0' or source.startswith(\n",
    "        'rtsp') or source.startswith('http') or source.endswith('.txt')\n",
    "\n",
    "    # Initialize\n",
    "    device = select_device(opt.device)\n",
    "    half &= device.type != 'cpu'  # half precision only supported on CUDA\n",
    "\n",
    "    # The MOT16 evaluation runs multiple inference streams in parallel, each one writing to\n",
    "    # its own .txt file. Hence, in that case, the output folder is not restored\n",
    "    if not evaluate:\n",
    "        if os.path.exists(out):\n",
    "            pass\n",
    "            shutil.rmtree(out)  # delete output folder\n",
    "        os.makedirs(out)  # make new output folder\n",
    "\n",
    "    # Directories\n",
    "    if type(yolo_model) is str:  # single yolo model\n",
    "        exp_name = yolo_model.split(\".\")[0]\n",
    "    elif type(yolo_model) is list and len(yolo_model) == 1:  # single models after --yolo_model\n",
    "        exp_name = yolo_model[0].split(\".\")[0]\n",
    "    else:  # multiple models after --yolo_model\n",
    "        exp_name = \"ensemble\"\n",
    "    exp_name = exp_name + \"_\" + deep_sort_model.split('/')[-1].split('.')[0]\n",
    "    save_dir = increment_path(Path(project) / exp_name, exist_ok=exist_ok)  # increment run if project name exists\n",
    "    (save_dir / 'tracks' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "    # Load model\n",
    "    model = DetectMultiBackend(yolo_model, device=device, dnn=opt.dnn)\n",
    "    stride, names, pt = model.stride, model.names, model.pt\n",
    "    imgsz = check_img_size(imgsz, s=stride)  # check image size\n",
    "\n",
    "    # Half\n",
    "    half &= pt and device.type != 'cpu'  # half precision only supported by PyTorch on CUDA\n",
    "    if pt:\n",
    "        model.model.half() if half else model.model.float()\n",
    "\n",
    "    # Set Dataloader\n",
    "    vid_path, vid_writer = None, None\n",
    "    # Check if environment supports image displays\n",
    "    if show_vid:\n",
    "        show_vid = check_imshow()\n",
    "\n",
    "    # Dataloader\n",
    "    if webcam:\n",
    "        show_vid = check_imshow()\n",
    "        cudnn.benchmark = True  # set True to speed up constant image size inference\n",
    "        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt)\n",
    "        nr_sources = len(dataset)\n",
    "    else:\n",
    "        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt)\n",
    "        nr_sources = 1\n",
    "    vid_path, vid_writer, txt_path = [None] * nr_sources, [None] * nr_sources, [None] * nr_sources\n",
    "\n",
    "    # initialize deepsort\n",
    "    cfg = get_config()\n",
    "    cfg.merge_from_file(opt.config_deepsort)\n",
    "\n",
    "    # Create as many trackers as there are video sources\n",
    "    deepsort_list = []\n",
    "    for i in range(nr_sources):\n",
    "        deepsort_list.append(\n",
    "            DeepSort(\n",
    "                deep_sort_model,\n",
    "                device,\n",
    "                max_dist=cfg.DEEPSORT.MAX_DIST,\n",
    "                max_iou_distance=cfg.DEEPSORT.MAX_IOU_DISTANCE,\n",
    "                max_age=cfg.DEEPSORT.MAX_AGE, n_init=cfg.DEEPSORT.N_INIT, nn_budget=cfg.DEEPSORT.NN_BUDGET,\n",
    "            )\n",
    "        )\n",
    "    outputs = [None] * nr_sources\n",
    "\n",
    "    # Get names and colors\n",
    "    names = model.module.names if hasattr(model, 'module') else model.names\n",
    "\n",
    "    # Run tracking\n",
    "    model.warmup(imgsz=(1 if pt else nr_sources, 3, *imgsz))  # warmup\n",
    "    dt, seen = [0.0, 0.0, 0.0, 0.0], 0\n",
    "    for frame_idx, (path, im, im0s, vid_cap, s) in enumerate(dataset):\n",
    "        t1 = time_sync()\n",
    "        im = torch.from_numpy(im).to(device)\n",
    "        im = im.half() if half else im.float()  # uint8 to fp16/32\n",
    "        im /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if len(im.shape) == 3:\n",
    "            im = im[None]  # expand for batch dim\n",
    "        t2 = time_sync()\n",
    "        dt[0] += t2 - t1\n",
    "\n",
    "        # Inference\n",
    "        visualize = increment_path(save_dir / Path(path[0]).stem, mkdir=True) if opt.visualize else False\n",
    "        pred = model(im, augment=opt.augment, visualize=visualize)\n",
    "        t3 = time_sync()\n",
    "        dt[1] += t3 - t2\n",
    "\n",
    "        # Apply NMS\n",
    "        pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, opt.classes, opt.agnostic_nms, max_det=opt.max_det)\n",
    "        dt[2] += time_sync() - t3\n",
    "\n",
    "        # Process detections\n",
    "        for i, det in enumerate(pred):  # detections per image\n",
    "            seen += 1\n",
    "            if webcam:  # nr_sources >= 1\n",
    "                p, im0, _ = path[i], im0s[i].copy(), dataset.count\n",
    "                p = Path(p)  # to Path\n",
    "                s += f'{i}: '\n",
    "                txt_file_name = p.name\n",
    "                save_path = str(save_dir / p.name)  # im.jpg, vid.mp4, ...\n",
    "            else:\n",
    "                p, im0, _ = path, im0s.copy(), getattr(dataset, 'frame', 0)\n",
    "                p = Path(p)  # to Path\n",
    "                # video file\n",
    "                if source.endswith(VID_FORMATS):\n",
    "                    txt_file_name = p.stem\n",
    "                    save_path = str(save_dir / p.name)  # im.jpg, vid.mp4, ...\n",
    "                # folder with imgs\n",
    "                else:\n",
    "                    txt_file_name = p.parent.name  # get folder name containing current img\n",
    "                    save_path = str(save_dir / p.parent.name)  # im.jpg, vid.mp4, ...\n",
    "\n",
    "            txt_path = str(save_dir / 'tracks' / txt_file_name)  # im.txt\n",
    "            s += '%gx%g ' % im.shape[2:]  # print string\n",
    "            imc = im0.copy() if save_crop else im0  # for save_crop\n",
    "\n",
    "            annotator = Annotator(im0, line_width=2, pil=not ascii)\n",
    "\n",
    "            if det is not None and len(det):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_coords(im.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "                # Print results\n",
    "                for c in det[:, -1].unique():\n",
    "                    n = (det[:, -1] == c).sum()  # detections per class\n",
    "                    s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "\n",
    "                xywhs = xyxy2xywh(det[:, 0:4])\n",
    "                confs = det[:, 4]\n",
    "                clss = det[:, 5]\n",
    "\n",
    "                # pass detections to deepsort\n",
    "                t4 = time_sync()\n",
    "                outputs[i] = deepsort_list[i].update(xywhs.cpu(), confs.cpu(), clss.cpu(), im0)\n",
    "                t5 = time_sync()\n",
    "                dt[3] += t5 - t4\n",
    "\n",
    "                # draw boxes for visualization\n",
    "                if len(outputs[i]) > 0:\n",
    "                    for j, (output, conf) in enumerate(zip(outputs[i], confs)):\n",
    "\n",
    "                        bboxes = output[0:4]\n",
    "                        id = output[4]\n",
    "                        cls = output[5]\n",
    "\n",
    "                        if save_txt:\n",
    "                            # to MOT format\n",
    "                            bbox_left = output[0]\n",
    "                            bbox_top = output[1]\n",
    "                            bbox_w = output[2] - output[0]\n",
    "                            bbox_h = output[3] - output[1]\n",
    "                            # Write MOT compliant results to file\n",
    "                            with open(txt_path + '.txt', 'a') as f:\n",
    "                                f.write(('%g ' * 10 + '\\n') % (frame_idx + 1, id, bbox_left,  # MOT format\n",
    "                                                               bbox_top, bbox_w, bbox_h, -1, -1, -1, i))\n",
    "\n",
    "                        if save_vid or save_crop or show_vid:  # Add bbox to image\n",
    "                            c = int(cls)  # integer class\n",
    "                            label = f'{id} {names[c]} {conf:.2f}'\n",
    "                            annotator.box_label(bboxes, label, color=colors(c, True))\n",
    "                            if save_crop:\n",
    "                                txt_file_name = txt_file_name if (isinstance(path, list) and len(path) > 1) else ''\n",
    "                                save_one_box(bboxes, imc, file=save_dir / 'crops' / txt_file_name / names[c] / f'{id}' / f'{p.stem}.jpg', BGR=True)\n",
    "\n",
    "                LOGGER.info(f'{s}Done. YOLO:({t3 - t2:.3f}s), DeepSort:({t5 - t4:.3f}s)')\n",
    "\n",
    "            else:\n",
    "                deepsort_list[i].increment_ages()\n",
    "                LOGGER.info('No detections')\n",
    "\n",
    "            # Stream results\n",
    "            im0 = annotator.result()\n",
    "            if show_vid:\n",
    "                cv2.imshow(str(p), im0)\n",
    "                cv2.waitKey(1)  # 1 millisecond\n",
    "\n",
    "            # Save results (image with detections)\n",
    "            if save_vid:\n",
    "                if vid_path[i] != save_path:  # new video\n",
    "                    vid_path[i] = save_path\n",
    "                    if isinstance(vid_writer[i], cv2.VideoWriter):\n",
    "                        vid_writer[i].release()  # release previous video writer\n",
    "                    if vid_cap:  # video\n",
    "                        fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "                        w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                        h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                    else:  # stream\n",
    "                        fps, w, h = 30, im0.shape[1], im0.shape[0]\n",
    "                    save_path = str(Path(save_path).with_suffix('.mp4'))  # force *.mp4 suffix on results videos\n",
    "                    vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
    "                vid_writer[i].write(im0)\n",
    "\n",
    "    # Print results\n",
    "    t = tuple(x / seen * 1E3 for x in dt)  # speeds per image\n",
    "    LOGGER.info(f'Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS, %.1fms deep sort update \\\n",
    "        per image at shape {(1, 3, *imgsz)}' % t)\n",
    "    if save_txt or save_vid:\n",
    "        s = f\"\\n{len(list(save_dir.glob('tracks/*.txt')))} tracks saved to {save_dir / 'tracks'}\" if save_txt else ''\n",
    "        LOGGER.info(f\"Results saved to {colorstr('bold', save_dir)}{s}\")\n",
    "    if update:\n",
    "        strip_optimizer(yolo_model)  # update model (to fix SourceChangeWarning)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--yolo_model', nargs='+', type=str, default='yolov5m.pt', help='model.pt path(s)')\n",
    "    parser.add_argument('--deep_sort_model', type=str, default='osnet_ibn_x1_0_MSMT17')\n",
    "    parser.add_argument('--source', type=str, default='0', help='source')  # file/folder, 0 for webcam\n",
    "    parser.add_argument('--output', type=str, default='inference/output', help='output folder')  # output folder\n",
    "    parser.add_argument('--imgsz', '--img', '--img-size', nargs='+', type=int, default=[640], help='inference size h,w')\n",
    "    parser.add_argument('--conf-thres', type=float, default=0.5, help='object confidence threshold')\n",
    "    parser.add_argument('--iou-thres', type=float, default=0.5, help='IOU threshold for NMS')\n",
    "    parser.add_argument('--fourcc', type=str, default='mp4v', help='output video codec (verify ffmpeg support)')\n",
    "    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
    "    parser.add_argument('--show-vid', action='store_true', help='display tracking video results')\n",
    "    parser.add_argument('--save-vid', action='store_true', help='save video tracking results')\n",
    "    parser.add_argument('--save-txt', action='store_true', help='save MOT compliant results to *.txt')\n",
    "    # class 0 is person, 1 is bycicle, 2 is car... 79 is oven\n",
    "    parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --class 0, or --class 16 17')\n",
    "    parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')\n",
    "    parser.add_argument('--augment', action='store_true', help='augmented inference')\n",
    "    parser.add_argument('--update', action='store_true', help='update all models')\n",
    "    parser.add_argument('--evaluate', action='store_true', help='augmented inference')\n",
    "    parser.add_argument(\"--config_deepsort\", type=str, default=\"deep_sort/configs/deep_sort.yaml\")\n",
    "    parser.add_argument(\"--half\", action=\"store_true\", help=\"use FP16 half-precision inference\")\n",
    "    parser.add_argument('--visualize', action='store_true', help='visualize features')\n",
    "    parser.add_argument('--max-det', type=int, default=1000, help='maximum detection per image')\n",
    "    parser.add_argument('--save-crop', action='store_true', help='save cropped prediction boxes')\n",
    "    parser.add_argument('--dnn', action='store_true', help='use OpenCV DNN for ONNX inference')\n",
    "    parser.add_argument('--project', default=ROOT / 'runs/track', help='save results to project/name')\n",
    "    parser.add_argument('--name', default='exp', help='save results to project/name')\n",
    "    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n",
    "    opt = parser.parse_args()\n",
    "    opt.imgsz *= 2 if len(opt.imgsz) == 1 else 1  # expand\n",
    "\n",
    "    with torch.no_grad():\n",
    "        detect(opt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
